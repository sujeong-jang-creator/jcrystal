{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data 모듈\n",
    "- 데이터 입력 파이프라인을 위한 모듈\n",
    "    - 모델 학습/평가을 위한 대용량 데이터셋을 제공(feeding)하기 위한 모듈\n",
    "    - raw dataset 에서 입력을 위한 전처리, 제공을 위한 배치, shuffling등을 한번에 처리할 수 있게 한다.\n",
    "- tf.data.Dataset 추상클래스에서 상속된 여러가지 클래스들을 제공\n",
    "    - 입력 소스의 제공 형태에 따라 다양한 방식을 제공\n",
    "\n",
    "\n",
    "## 데이터셋 API 사용\n",
    "1. <span style='font-size:1.2em;font-weight:bolder'>Dataset 생성</span>\n",
    "    - raw dataset을 지정\n",
    "    - from_tensor_slices(), from_generator() 클래스 메소드, tf.data.TFRecordDataset 클래스등를 사용해 메모리나 파일에 있는 데이터를 Dataset으로 만든다.\n",
    "    - from_tensor_slices(): 리스트 넘파이배열, 텐서플로 자료형에서 데이터를 생성한다.\n",
    "2. <span style='font-size:1.2em;font-weight:bolder'>제공 데이터 전처리</span>\n",
    "    - map(함수) : 하나 하나의 데이터를 변환\n",
    "        - 함수: 값을 변환할 함수로 입력데이터셋의 개수만큼 매개변수 선언\n",
    "    - filter(함수): 특정 조건의 데이터만 제공하도록 처리.\n",
    "        - - 함수: 제공할 값의 조건을 정의한 함수로 입력데이터셋의 개수만큼 매개변수 선언하고 bool 값을 반환.\n",
    "3. <span style='font-size:1.2em;font-weight:bolder'>Dataset을 사용해 데이터 제공</span>\n",
    "    - batch(), shuffle()을 이용해 제공 방식 지정\n",
    "        - batch(size): 학습/평가시 한번에 제공할 batch size 지정\n",
    "            - size: int. batch size 지정\n",
    "            - drop_remainder: bool. True일 경우 마지막 제공시 남은 데이터수가 batch size보다 작으면 제공하지 않는다.\n",
    "    -  shuffle(buffer 크기): dataset의 원소들의 순서를 섞는다. \n",
    "        - buffer 크기: int. buffer 크기는 섞는 공간의 크기로  **데이터보다 크거나 같으면** 완전셔플, **적으면 일부만 가져와서 섞어** 완전셔플이 안된다.\n",
    "        - 데이터 사이즈가 너무 커서 메모리가 부족할 경우 버퍼크기를 적게 준다.\n",
    "        - 메모리가 충분하다면 데이터의 개수와 동일하게 주면된다.\n",
    "    - repeat(count): 전체 데이터를 한번 다 제공한 뒤 다시 데이터를 제공한다.\n",
    "        - count: 몇번 제공할지 반복 횟수\n",
    "        - shuffle이 적용된 Dataset의 경우 다음 반복 제공마다 shuffle을 진행한다.\n",
    "        \n",
    "### Dataset 메소드\n",
    "- take(개수): 지정한 개수만큼의 데이터만 제공한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = np.arange(10)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(raw_data)\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Dataset으로 부터 값 조회\n",
    "# take()함수사용-원하는 개수만큼, 반복문 (Dataset=>Iterable타입)-전체조회\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data2 = np.arange(10,20)\n",
    "raw_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32) tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(13, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32) tf.Tensor(15, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32) tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32) tf.Tensor(17, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32) tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32) tf.Tensor(19, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 학습- model.fit(X, y)\n",
    "# raw_data: X_train, raw_data2: y_train\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices((raw_data, raw_data2)) \n",
    "for X, y in dataset2:\n",
    "    print(X, y)\n",
    "#     print(type(data))\n",
    "#     print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "print(raw_data)\n",
    "print(raw_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.take(개수): 지정한 개수만큼만 조회\n",
    "dataset3 = dataset.take(3) #dataset으로 부터 3개\n",
    "print(type(dataset3))\n",
    "for data in dataset3:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ShuffleDataset'>\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.shuffle(buffer_size:정수) : dataset의 원소들을 섞어준다. buffer_size는 메모리가 허용하는 한 raw_data와 같은 개수로 지정.\n",
    "dataset4 = dataset.shuffle(10) \n",
    "print(type(dataset4))\n",
    "for data in dataset4:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "tf.Tensor([0 1 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3 4 5], shape=(3,), dtype=int32)\n",
      "tf.Tensor([6 7 8], shape=(3,), dtype=int32)\n",
      "tf.Tensor([9], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.batch(batch_size): 한번에 제공하는 데이터의 개수\n",
    "dataset5 = dataset.batch(3)  # 한번에 3개씩 제공\n",
    "print(type(dataset5))\n",
    "for data in dataset5:\n",
    "    print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 6 5], shape=(3,), dtype=int32)\n",
      "tf.Tensor([7 2 4], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3 9 8], shape=(3,), dtype=int32)\n",
      "tf.Tensor([1], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 기본 dataset + shuffle + batch \n",
    "# a = dataset.shuffle(10)\n",
    "# b = a.batch(3)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(raw_data)\n",
    "\n",
    "dataset6 = dataset.shuffle(10).batch(3)\n",
    "for d in dataset6:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.RepeatDataset'>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.repeat(count) # 전체 데이터셋을 count 만큼 반복해서 제공, count 생략하면 무한제공\n",
    "dataset7 = dataset.repeat(3) #3번 반복해서 제공\n",
    "print(type(dataset7))\n",
    "for data in dataset7:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 7 6 3 2], shape=(5,), dtype=int32)\n",
      "tf.Tensor([5 1 4 9 8], shape=(5,), dtype=int32)\n",
      "tf.Tensor([2 9 3 1 8], shape=(5,), dtype=int32)\n",
      "tf.Tensor([6 4 5 0 7], shape=(5,), dtype=int32)\n",
      "tf.Tensor([2 9 7 6 1], shape=(5,), dtype=int32)\n",
      "tf.Tensor([3 5 0 4 8], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 여러번 반복해서(repeat) 값을 제공할 경우 반복을 시작할 때 마다 shuffle을 한다.\n",
    "dataset8 = dataset.shuffle(10).batch(5).repeat(3)\n",
    "for data in dataset8:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 회귀 - Boston Housing Dataset\n",
    "보스턴 주택가격 dataset은 다음과 같은 속성을 바탕으로 해당 타운 주택 가격의 중앙값을 예측하는 문제.\n",
    "- CRIM: 범죄율\n",
    "- ZN: 25,000 평방피트당 주거지역 비율\n",
    "- INDUS: 비소매 상업지구 비율\n",
    "- CHAS: 찰스강에 인접해 있는지 여부(인접:1, 아니면:0)\n",
    "- NOX: 일산화질소 농도(단위: 0.1ppm)\n",
    "- RM: 주택당 방의 수\n",
    "- AGE: 1940년 이전에 건설된 주택의 비율\n",
    "- DIS: 5개의 보스턴 직업고용센터와의 거리(가중 평균)\n",
    "- RAD: 고속도로 접근성\n",
    "- TAX: 재산세율\n",
    "- PTRATIO: 학생/교사 비율\n",
    "- B: 흑인 비율\n",
    "- LSTAT: 하위 계층 비율\n",
    "\n",
    "예측해야하는 것\n",
    "- MEDV: 타운의 주택가격 중앙값(단위: 1,000달러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification\n",
    "\n",
    "### Fashion MNIST(MNIST) Dataset - 다중분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋. \n",
    "이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 의류 품목을 나타낸다:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>그림</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "패션 MNIST와 손글씨 MNIST는  비교적 작기 때문에 알고리즘의 작동 여부를 확인하기 위해 사용되곤 하며 코드를 테스트하고 디버깅하는 용도로 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지는 28x28 크기의 넘파이 배열이고 픽셀 값은 0과 255 사이이다. *레이블*(label)은 0에서 9까지의 정수 배열이다. 아래 표는 이미지에 있는 의류의 **클래스**(class)를 나낸다.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>레이블</th>\n",
    "    <th>클래스</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trousers</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "각 이미지는 하나의 레이블에 매핑되어 있다. 데이터셋에 클래스 이름이 들어있지 않기 때문에 나중에 이미지를 출력할 때 사용하기 위해 별도의 변수를 만들어 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:13:37.059205Z",
     "start_time": "2021-04-14T09:13:37.050854Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위스콘신 유방암 데이터셋 - 이진분류 문제\n",
    "- 위스콘신 대학교에서 제공한 종양의 악성/양성여부 분류를 위한 데이터셋\n",
    "- Feature\n",
    "    - 종양에 대한 다양한 측정값들\n",
    "- Target의 class\n",
    "    - 0 - malignant(악성종양)\n",
    "    - 1 - benign(양성종양)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
